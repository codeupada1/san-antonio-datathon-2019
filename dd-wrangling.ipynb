{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import acquire\n",
    "import pandas as pd\n",
    "\n",
    "# data visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from datetime import timedelta, datetime\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACQUIRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.read_data('saws-ssos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_col(df):\n",
    "    \"\"\"\n",
    "    Write or use a previously written function to return the\n",
    "    total missing values and the percent missing values by column.\n",
    "    \"\"\"\n",
    "    null_count = df.isnull().sum()\n",
    "    null_percentage = (null_count / df.shape[0]) * 100\n",
    "    empty_count = pd.Series(((df == ' ') | (df == '')).sum())\n",
    "    empty_percentage = (empty_count / df.shape[0]) * 100\n",
    "    nan_count = pd.Series(((df == 'nan') | (df == 'NaN')).sum())\n",
    "    nan_percentage = (nan_count / df.shape[0]) * 100\n",
    "    return pd.DataFrame({'num_missing': null_count, 'missing_percentage': null_percentage,\n",
    "                         'num_empty': empty_count, 'empty_percentage': empty_percentage,\n",
    "                         'nan_count': nan_count, 'nan_percentage': nan_percentage})\n",
    "\n",
    "\n",
    "def missing_values_row(df):\n",
    "    \"\"\"\n",
    "    Write or use a previously written function to return the\n",
    "    total missing values and the percent missing values by row.\n",
    "    \"\"\"\n",
    "    null_count = df.isnull().sum(axis=1)\n",
    "    null_percentage = (null_count / df.shape[1]) * 100\n",
    "    return pd.DataFrame({'num_missing': null_count, 'percentage': null_percentage})\n",
    "\n",
    "\n",
    "def handle_missing_threshold(df, prop_required_column = .3, prop_required_row = .9):\n",
    "    \"\"\"\n",
    "    Removes columns and rows whose count of missing values exceeds threshold.\n",
    "    \"\"\"\n",
    "    threshold = int(round(prop_required_column*len(df.index),0))\n",
    "    df.dropna(axis=1, thresh=threshold, inplace=True)\n",
    "    threshold = int(round(prop_required_row*len(df.columns),0))\n",
    "    df.dropna(axis=0, thresh=threshold, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def count_val(column):\n",
    "    return df[column].value_counts(dropna=False)\n",
    "\n",
    "def remove_columns(df, columns):\n",
    "    return df.drop(columns=columns)\n",
    "\n",
    "def fill_with_zeroes(df, *cols):\n",
    "    \"\"\"\n",
    "    Write a function that will take a dataframe and list of\n",
    "    column names as input and return the dataframe with the\n",
    "    null values in those columns replace by 0.\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        df[col] = df[col].fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def fill_with_median(df, *cols):\n",
    "    \"\"\"\n",
    "    Fill the NaN values with respective median values.\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n",
    "\n",
    "\n",
    "def fill_with_none(df, *cols):\n",
    "    \"\"\"\n",
    "    Fill the NaN values with 'None' string value.\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        df[col] = df[col].fillna('None')\n",
    "    return df\n",
    "\n",
    "def fill_with_unknown(df, *cols):\n",
    "    \"\"\"\n",
    "    Fill the NaN values with 'None' string value.\n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        df[col] = df[col].fillna('Unknown')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Let's take a look at missing values._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "missing_values_col(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SPILL ADDRESS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_values_row(df).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Decided to handle missing a different way, maybe\n",
    "# some feature engineering or something...\n",
    "# df = handle_missing_threshold(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_val('ResponseTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Let's remove variables that do not add information._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_columns(df, columns=['INSPKEY',\n",
    "                                 'SERVNO',\n",
    "                                 'REPORTDATE',\n",
    "                                 'FERGUSON',\n",
    "                                 'Month',\n",
    "                                 'Year',\n",
    "                                 'Week',\n",
    "                                 'EARZ_ZONE',\n",
    "                                 'DWNDPTH',\n",
    "                                 'UPSDPTH',\n",
    "                                 'Inches_No',\n",
    "                                 'RainFall_Less3',\n",
    "                                 'SewerAssetExp',\n",
    "                                 'UNITID',\n",
    "                                 'UNITID2',\n",
    "                                 'COUNCIL_DISTRICT',\n",
    "                                 'INSTYEAR',\n",
    "                                 'Public Notice',\n",
    "                                 'TIMEINT',\n",
    "                                 'HRS_2',\n",
    "                                 'GAL_2',\n",
    "                                 'HRS_3',\n",
    "                                 'GAL_3',\n",
    "                                 'SPILL_START_2',\n",
    "                                 'SPILL_STOP_2',\n",
    "                                 'SPILL_START_3',\n",
    "                                 'SPILL_STOP_3',\n",
    "                                 'SPILL ADDRESS',\n",
    "                                 'SPILL_ADDRESS',\n",
    "                                 'SPILL_ST_NAME',\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fill_with_unknown(df, 'DISCHARGE_ROUTE',\n",
    "                      'ACTIONS',\n",
    "                      'COMMENTS',\n",
    "                      'DISCHARGE_TO',\n",
    "                      'Expr1029',\n",
    "                      'PIPETYPE',\n",
    "                      'UNITTYPE',\n",
    "                      'ASSETTYPE',\n",
    "                      'Root_Cause',\n",
    "                      'STEPS_TO_PREVENT',\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fill_with_median(df, 'GALSRET',\n",
    "                     'HRS',\n",
    "                     'PIPEDIAM',\n",
    "                     'PIPELEN',\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_val('ResponseTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_val('ResponseDTTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_columns(df, columns=['ResponseTime',\n",
    "                                 'ResponseDTTM',\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_col(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Let's temporarily remove the columns that needs to be feature-engineered later._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = remove_columns(df, columns=['PIPETYPE',\n",
    "                                  'NUM_SPILLS_24MOS',\n",
    "                                  'PREVSPILL_24MOS',\n",
    "                                  'UNITTYPE',\n",
    "                                  'LASTCLND',\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_col(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df0.rename(index=str, columns={\"Expr1029\": \"EXPR1029\", \"Root_Cause\": \"ROOT_CAUSE\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df0[:'2016']\n",
    "test = df0['2016':]\n",
    "print(train.nunique())\n",
    "print(test.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.SPILL_START = pd.to_datetime(df0.SPILL_START,infer_datetime_format=True)\n",
    "df0.SPILL_STOP = pd.to_datetime(df0.SPILL_STOP,infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df0.sort_values('SPILL_START')\n",
    "df0 = df0.set_index('SPILL_START')\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_date = df0.groupby(['SPILL_START'])['TOTAL_GAL'].sum().reset_index()\n",
    "by_date.plot(x='SPILL_START', y='TOTAL_GAL');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.groupby(['SPILL_START']).TOTAL_GAL.sum().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.resample('A').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:'2016']\n",
    "test = df['2017':]\n",
    "print(train.nunique())\n",
    "print(test.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_col(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_col(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overflow = train.resample('D').TOTAL_GAL.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overflow.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overflow.resample('M').mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overflow.resample('Q').mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overflow.rolling(5).mean().plot(figsize=(12, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overflow.diff(periods=10).plot(figsize=(12, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = sm.tsa.seasonal_decompose(overflow.dropna(), model='additive', freq=12)\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.lag_plot(overflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = pd.concat([overflow.shift(1), overflow], axis=1)\n",
    "df_corr.columns = ['t-1','t+1']\n",
    "result = df_corr.corr()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
